{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59dc3f32",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.019523,
     "end_time": "2023-11-20T18:03:28.972064",
     "exception": false,
     "start_time": "2023-11-20T18:03:28.952541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f0cc78",
   "metadata": {
    "papermill": {
     "duration": 13.777656,
     "end_time": "2023-11-20T18:03:42.758467",
     "exception": false,
     "start_time": "2023-11-20T18:03:28.980811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# import data handling tools \u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import itertools\n",
    "\n",
    "# import data handling tools \n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import matplotlib.pyplot as plt\n",
    "# import Deep learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization,GlobalAveragePooling2D, Add, Multiply\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print ('modules loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f796a06c",
   "metadata": {
    "papermill": {
     "duration": 5.498143,
     "end_time": "2023-11-20T18:03:48.265269",
     "exception": false,
     "start_time": "2023-11-20T18:03:42.767126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = r'F:\\MV\\Dataset\\HAM1000\\hmnist_28_28_RGB.csv'\n",
    "data = pd.read_csv(data_dir)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac3419f-5789-457a-a995-50a807ea7aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0adcb8d",
   "metadata": {
    "papermill": {
     "duration": 0.110948,
     "end_time": "2023-11-20T18:03:48.385458",
     "exception": false,
     "start_time": "2023-11-20T18:03:48.274510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Label = data[\"label\"]\n",
    "Data = data.drop(columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779c31b",
   "metadata": {
    "papermill": {
     "duration": 0.025722,
     "end_time": "2023-11-20T18:03:48.420456",
     "exception": false,
     "start_time": "2023-11-20T18:03:48.394734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4aeb34",
   "metadata": {
    "papermill": {
     "duration": 3.928484,
     "end_time": "2023-11-20T18:03:52.357791",
     "exception": false,
     "start_time": "2023-11-20T18:03:48.429307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "oversample = RandomOverSampler()\n",
    "Data, Label  = oversample.fit_resample(Data, Label)\n",
    "Data = np.array(Data).reshape(-1, 28, 28, 3)\n",
    "print('Shape of Data :', Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e90ae8",
   "metadata": {
    "papermill": {
     "duration": 0.021587,
     "end_time": "2023-11-20T18:03:52.388539",
     "exception": false,
     "start_time": "2023-11-20T18:03:52.366952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Label = np.array(Label)\n",
    "Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e518cb6",
   "metadata": {
    "papermill": {
     "duration": 0.020228,
     "end_time": "2023-11-20T18:03:52.418121",
     "exception": false,
     "start_time": "2023-11-20T18:03:52.397893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = {4: ('nv', ' melanocytic nevi'),\n",
    "           6: ('mel', 'melanoma'),\n",
    "           2: ('bkl', 'benign keratosis-like lesions'), \n",
    "           1:('bcc' , ' basal cell carcinoma'),\n",
    "           5: ('vasc', ' pyogenic granulomas and hemorrhage'),\n",
    "           0: ('akiec', 'Actinic keratoses and intraepithelial carcinomae'),\n",
    "           3: ('df', 'dermatofibroma')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16b6f8",
   "metadata": {
    "papermill": {
     "duration": 1.926467,
     "end_time": "2023-11-20T18:03:54.353943",
     "exception": false,
     "start_time": "2023-11-20T18:03:52.427476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(Data , Label , test_size = 0.25 , random_state = 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425987e9",
   "metadata": {
    "papermill": {
     "duration": 0.020381,
     "end_time": "2023-11-20T18:03:54.384326",
     "exception": false,
     "start_time": "2023-11-20T18:03:54.363945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ae56d1",
   "metadata": {
    "papermill": {
     "duration": 0.019608,
     "end_time": "2023-11-20T18:03:54.413572",
     "exception": false,
     "start_time": "2023-11-20T18:03:54.393964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f1f06",
   "metadata": {
    "papermill": {
     "duration": 0.020389,
     "end_time": "2023-11-20T18:03:54.443370",
     "exception": false,
     "start_time": "2023-11-20T18:03:54.422981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=(1./255)\n",
    "                             ,rotation_range=10\n",
    "                             ,zoom_range = 0.1\n",
    "                             ,width_shift_range=0.1\n",
    "                             ,height_shift_range=0.1)\n",
    "\n",
    "testgen = ImageDataGenerator(rescale=(1./255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41546902",
   "metadata": {
    "papermill": {
     "duration": 0.019312,
     "end_time": "2023-11-20T18:03:54.471883",
     "exception": false,
     "start_time": "2023-11-20T18:03:54.452571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy'\n",
    "                                            , patience = 2\n",
    "                                            , verbose=1\n",
    "                                            ,factor=0.5\n",
    "                                            , min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba3455b",
   "metadata": {
    "papermill": {
     "duration": 0.896561,
     "end_time": "2023-11-20T18:03:55.377689",
     "exception": false,
     "start_time": "2023-11-20T18:03:54.481128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, Add, GlobalAveragePooling2D, Dense\n",
    "\n",
    "def squeeze_excitation_block(x, ratio=8):\n",
    "    channels = int(x.shape[-1])\n",
    "    se = GlobalAveragePooling2D()(x)\n",
    "    se = Dense(channels // ratio, activation='relu')(se)\n",
    "    se = Dense(channels, activation='sigmoid')(se)\n",
    "    se = tf.keras.layers.Reshape((1, 1, channels))(se)\n",
    "    scaled = Multiply()([x, se])\n",
    "    return scaled\n",
    "    \n",
    "def residual_block(x, filters, kernel_size=3, strides=1):\n",
    "    # Shortcut connection\n",
    "    shortcut = x\n",
    "\n",
    "    # First convolutional layer\n",
    "    x = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Second convolutional layer\n",
    "    x = Conv2D(filters, kernel_size=kernel_size, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Shortcut connection\n",
    "    if strides != 1 or shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, kernel_size=1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    # Element-wise addition\n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet(input_shape, num_classes, num_blocks=[2, 2, 2, 2]):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    # Initial convolutional layer\n",
    "    x = Conv2D(64, (7, 7), strides=2, padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Residual blocks\n",
    "    for block_num in range(len(num_blocks)):\n",
    "        filters = 64 * (2 ** block_num)\n",
    "        for _ in range(num_blocks[block_num]):\n",
    "            if block_num > 0 and _ == 0:\n",
    "                # Downsample for the first block in each group (except the first group)\n",
    "                x = residual_block(x, filters, strides=2)\n",
    "            else:\n",
    "                x = residual_block(x, filters)\n",
    "\n",
    "    # Global average pooling and dense layer\n",
    "    x = squeeze_excitation_block(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output_tensor = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ebadf-f169-444a-bfd2-f1289503c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input shape and number of classes\n",
    "input_shape = (28, 28, 3)  # Example input shape, adjust based on your requirements\n",
    "num_classes = 7  # Adjust based on your classification task\n",
    "\n",
    "# Create the ResNet model\n",
    "model = resnet(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674dcbb6",
   "metadata": {
    "papermill": {
     "duration": 1306.438779,
     "end_time": "2023-11-20T18:25:41.833059",
     "exception": false,
     "start_time": "2023-11-20T18:03:55.394280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "history = model.fit(X_train ,\n",
    "                    y_train ,\n",
    "                    epochs=2 ,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(X_test , y_test) ,\n",
    "                    callbacks=[learning_rate_reduction,EarlyStopping(monitor='loss', patience=10, restore_best_weights = True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08cedc-2140-4105-ad5f-b37a0293dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Concatenate, GlobalAveragePooling2D, Dense, Multiply, BatchNormalization, ReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Your model definition (inception_resnet) here...\n",
    "\n",
    "# Load the CIFAR-10 data for demonstration purposes\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize and preprocess the data\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Your model instantiation here...\n",
    "model = inception_resnet(input_shape=(32, 32, 3), num_classes=10)\n",
    "\n",
    "# Your model training here...\n",
    "\n",
    "# Function to generate Grad-CAM heatmap\n",
    "def generate_grad_cam(model, img_array, layer_name):\n",
    "    grad_model = Model(inputs=model.input, outputs=(model.get_layer(layer_name).output, model.output))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        class_output = predictions[:, np.argmax(predictions[0])]\n",
    "\n",
    "    grads = tape.gradient(class_output, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# Select an image for Grad-CAM visualization\n",
    "sample_img = X_test[0]\n",
    "sample_img_array = np.expand_dims(sample_img, axis=0)\n",
    "\n",
    "# Get the Grad-CAM heatmap\n",
    "attention_map = generate_grad_cam(model, sample_img_array, 'name_of_last_conv_layer')\n",
    "\n",
    "# Resize the heatmap to match the original image size\n",
    "attention_map_resized = cv2.resize(attention_map, (sample_img.shape[1], sample_img.shape[0]))\n",
    "attention_map_resized = np.maximum(attention_map_resized, 0)  # ReLU on the heatmap\n",
    "attention_map_resized /= np.max(attention_map_resized)  # Normalize to [0, 1]\n",
    "\n",
    "# Superimpose the heatmap on the original image\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * attention_map_resized), cv2.COLORMAP_JET)\n",
    "superimposed_img = cv2.addWeighted(sample_img, 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "# Display the original image, Grad-CAM heatmap, and superimposed image\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(sample_img)\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(attention_map_resized, cmap='jet', alpha=0.8)\n",
    "plt.title('Grad-CAM Heatmap')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(superimposed_img)\n",
    "plt.title('Superimposed Image with Grad-CAM')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb91ad5-fdd6-4e21-a4f3-0366af979402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#model.save_weights('weights\\ResNetAttention.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c5503",
   "metadata": {
    "papermill": {
     "duration": 0.293671,
     "end_time": "2023-11-20T18:25:42.393925",
     "exception": false,
     "start_time": "2023-11-20T18:25:42.100254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_training(hist):\n",
    "    tr_acc = hist.history['accuracy']\n",
    "    tr_loss = hist.history['loss']\n",
    "    val_acc = hist.history['val_accuracy']\n",
    "    val_loss = hist.history['val_loss']\n",
    "    index_loss = np.argmin(val_loss)\n",
    "    val_lowest = val_loss[index_loss]\n",
    "    index_acc = np.argmax(val_acc)\n",
    "    acc_highest = val_acc[index_acc]\n",
    "\n",
    "    plt.figure(figsize= (20, 8))\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    Epochs = [i+1 for i in range(len(tr_acc))]\n",
    "    loss_label = f'best epoch= {str(index_loss + 1)}'\n",
    "    acc_label = f'best epoch= {str(index_acc + 1)}'\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
    "    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
    "    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
    "    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
    "    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba96f3",
   "metadata": {
    "papermill": {
     "duration": 1.187868,
     "end_time": "2023-11-20T18:25:43.847692",
     "exception": false,
     "start_time": "2023-11-20T18:25:42.659824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da07c753",
   "metadata": {
    "papermill": {
     "duration": 41.464997,
     "end_time": "2023-11-20T18:26:25.656002",
     "exception": false,
     "start_time": "2023-11-20T18:25:44.191005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_score = model.evaluate(X_train, y_train, verbose= 1)\n",
    "test_score = model.evaluate(X_test, y_test, verbose= 1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa5e0da",
   "metadata": {
    "papermill": {
     "duration": 11.319973,
     "end_time": "2023-11-20T18:26:37.315854",
     "exception": false,
     "start_time": "2023-11-20T18:26:25.995881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true = np.array(y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred = np.argmax(y_pred , axis=1)\n",
    "y_true = np.argmax(y_true , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21ad8c",
   "metadata": {
    "papermill": {
     "duration": 0.371808,
     "end_time": "2023-11-20T18:26:38.052179",
     "exception": false,
     "start_time": "2023-11-20T18:26:37.680371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes_labels = []\n",
    "for key in classes.keys():\n",
    "    classes_labels.append(key)\n",
    "\n",
    "print(classes_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a04b7",
   "metadata": {
    "papermill": {
     "duration": 1.150624,
     "end_time": "2023-11-20T18:26:39.559413",
     "exception": false,
     "start_time": "2023-11-20T18:26:38.408789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm = cm = confusion_matrix(y_true, y_pred, labels=classes_labels)\n",
    "\n",
    "plt.figure(figsize= (10, 10))\n",
    "plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation= 45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060744f",
   "metadata": {
    "papermill": {
     "duration": 0.596684,
     "end_time": "2023-11-20T18:26:40.514687",
     "exception": false,
     "start_time": "2023-11-20T18:26:39.918003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.save('Skin Cancer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb32b2b",
   "metadata": {
    "papermill": {
     "duration": 0.364649,
     "end_time": "2023-11-20T18:26:41.240370",
     "exception": false,
     "start_time": "2023-11-20T18:26:40.875721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 54339,
     "sourceId": 104884,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1400.093646,
   "end_time": "2023-11-20T18:26:44.411951",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-20T18:03:24.318305",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
